{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from utils.data_loader import Dataset\n",
    "from utils.helpers import * \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR \n",
    "import xgboost\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#first merge test cc files\n",
    "cc1 = pd.read_csv('./data/cc_testing_v2.csv')\n",
    "cc2 = pd.read_csv('./data/cc_testing2_v2.csv')\n",
    "cc_merged = pd.merge(cc1, cc2, how='outer')\n",
    "cc_merged.to_csv('./data/cc_testing_merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_filenames = ['./data/training_fluid_intelligenceV1.csv', './data/btsv01_ALL.txt', './data/cc_training_v2.csv']\n",
    "validation_filenames = ['./data/validation_fluid_intelligenceV1.csv', './data/btsv01_ALL.txt', './data/cc_validation_v2.csv']\n",
    "test_filenames = ['./data/btsv01_ALL.txt', './data/cc_testing_merged.csv']\n",
    "\n",
    "cols_to_drop = ['btsv01_id', 'interview_date', 'collection_id', 'dataset_id', 'collection_title', \\\n",
    "                'src_subject_id', 'gender']\n",
    "\n",
    "label_col = 'residual_fluid_intelligence_score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2885: DtypeWarning: Columns (0,1,2,6,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training = Dataset(training_filenames, cols_to_drop, label_col)\n",
    "validation = Dataset(validation_filenames, cols_to_drop, label_col)\n",
    "test = Dataset(test_filenames, cols_to_drop, label_col, test=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_data = scaler.fit_transform(training.data)\n",
    "val_data = scaler.transform(validation.data)\n",
    "test_data = scaler.transform(test.data)\n",
    "dataset_cols = training.meta_data['final_dataset']['columns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#generating custom columns\n",
    "is_frontal = np.array([x for x in range(train_data.shape[1]) if 'frontal' in training.meta_data['final_dataset']['columns'][x]])\n",
    "is_suptent = np.array([x for x in range(train_data.shape[1]) if 'supratentorium' in training.meta_data['final_dataset']['columns'][x]])\n",
    "structures_to_delete = ['interview_age', 'thalamus', 'caudate', 'putamen', 'pallidum', 'volume', 'wm', 'supratentorium', 'csf']\n",
    "cortex_indices = []\n",
    "\n",
    "#first 123 are in the initial dataset \n",
    "for i,column in enumerate(training.meta_data['final_dataset']['columns'][:123]):\n",
    "    curr_deletes = []\n",
    "    for name in structures_to_delete: \n",
    "        if name in column:\n",
    "            curr_deletes.append(name)\n",
    "    if len(curr_deletes)==0:\n",
    "        cortex_indices.append(i)\n",
    "\n",
    "cortex_indices = np.array(cortex_indices)\n",
    "def generate_frontal_ratio(frontal_inds, reference_inds, data):\n",
    "    coefs = []\n",
    "    for observation in data:\n",
    "        frontal_volume = np.sum(observation[frontal_inds])\n",
    "        reference_volume = np.sum(observation[reference_inds])\n",
    "        coefs.append(frontal_volume/reference_volume)\n",
    "    return np.array(coefs).reshape(-1,1)\n",
    "\n",
    "\n",
    "frontal_suptent_train = scaler.fit_transform(generate_frontal_ratio(is_frontal, is_suptent, train_data))\n",
    "frontal_suptent_val = scaler.transform(generate_frontal_ratio(is_frontal, is_suptent, val_data))\n",
    "frontal_suptent_test = scaler.transform(generate_frontal_ratio(is_frontal, is_suptent, test_data))\n",
    "frontal_cortex_train= scaler.fit_transform(generate_frontal_ratio(is_frontal, cortex_indices, train_data))\n",
    "frontal_cortex_val = scaler.transform(generate_frontal_ratio(is_frontal, cortex_indices, val_data))\n",
    "frontal_cortex_test = scaler.transform(generate_frontal_ratio(is_frontal, cortex_indices, test_data))\n",
    "\n",
    "#append to cols and to data\n",
    "dataset_cols = training.meta_data['final_dataset']['columns']\n",
    "dataset_cols.extend(['frontal_suptent_ratio', 'frontal_cortex_ratio'])\n",
    "train_data = np.append(train_data, np.hstack((frontal_suptent_train, frontal_cortex_train)), axis=1)\n",
    "val_data = np.append(val_data, np.hstack((frontal_suptent_val, frontal_cortex_val)), axis=1)\n",
    "test_data = np.append(test_data, np.hstack((frontal_suptent_test, frontal_cortex_test)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "today = str(datetime.date.today()) + \"_default+cc\"\n",
    "results_file = './data/results_{}.pkl'.format(today)\n",
    "results_df = pd.read_pickle(results_file)\n",
    "columns_variants = './data/variants_mapping_{}.pkl'.format(today)\n",
    "cols_variants = pd.read_pickle(columns_variants)\n",
    "features_imp_file = './data/feature_importance_{}randfor.pkl'.format(today)\n",
    "feature_imp_df = pd.read_pickle(features_imp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_features_comb = 0\n",
    "best_val = 100\n",
    "best_model = None\n",
    "for feature_comb in results_df.keys():\n",
    "    if type(results_df[feature_comb])==dict:\n",
    "        for model in results_df[feature_comb].keys():\n",
    "            if results_df[feature_comb][model] < best_val:\n",
    "                best_val = results_df[feature_comb][model]\n",
    "                best_model = model\n",
    "                best_features_comb = feature_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 70.98327127079955 randfor\n"
     ]
    }
   ],
   "source": [
    "print(best_features_comb, best_val, best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get the columns\n",
    "valid_inds = cols_variants[best_features_comb]\n",
    "n_best = len(np.where(feature_imp_df['feature_importance'] >=0.01)[0])\n",
    "inds_restricted = np.argsort(-feature_imp_df['feature_importance'])[:n_best]\n",
    "model = RandomForestRegressor(n_estimators=500, n_jobs=-1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(train_data[:,inds_restricted], training.labels)\n",
    "test_predictions = model.predict(test_data[:,inds_restricted])\n",
    "val_predictions = model.predict(val_data[:,inds_restricted])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68.40265187472134"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(val_predictions, validation.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_results_df = pd.DataFrame(np.array([test.subjects.values, test_predictions]).T, columns=['subject', 'predicted_score'], index=None)\n",
    "val_results_df = pd.DataFrame(np.array([validation.subjects.values, val_predictions]).T, columns=['subject', 'predicted_score'], index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_template = pd.read_csv('./data/abcdnp_testing_template.csv')\n",
    "val_template = pd.read_csv('./data/pred_validation_template.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_final = pd.merge(test_template, test_results_df, on='subject', suffixes=('_',''), how='inner')\n",
    "test_final = test_final.drop([x for x in test_final.columns if x.endswith('_')], axis=1)\n",
    "if save:\n",
    "    test_final.to_csv('./data/abcdnp_testing_template.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_final = pd.merge(val_template, val_results_df, on='subject', suffixes=('_', ''))\n",
    "val_final = val_final.drop([x for x in val_final.columns if x.endswith('_')], axis=1)\n",
    "if save: \n",
    "    val_final.to_csv('./data/pred_validation_template.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
